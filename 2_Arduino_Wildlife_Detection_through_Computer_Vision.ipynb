{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhakrishnan-omotec/wildlife-repo/blob/main/2_Arduino_Wildlife_Detection_through_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0wUFauF1W89"
      },
      "source": [
        "<a id='step1'></a>\n",
        "## Step 1: Import Dataset and Libraries\n",
        "\n",
        "Our fist step is to import all the libraries used in this project."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_l3VzKyr-8L",
        "outputId": "8e28d172-0072-4134-f4bb-53cdad8223c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj5M3px0NJiq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
        "import torchvision\n",
        "from torch.utils.data import (Dataset, DataLoader)  # Gives easier dataset managment and creates mini batches\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.models as models"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvM0XKXwo52E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38eec85d-08ea-43b0-ec1c-7de9004f5189"
      },
      "source": [
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print (\"cuda availability : \",use_cuda)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda availability :  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPEvLk8eNj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d45b342-d1c7-4722-d7c2-4292f5d01da8"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # convolutional layer (sees 224 x 224 x 3 image tensor)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        # convolutional layer (sees 122 x 122 x 16 tensor)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        # convolutional layer (sees 56 x 56 x 32 tensor)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        # convolutional layer (sees 28 x 28 x 64 tensor)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        # convolutional layer (sees 14 x 14 x 128 tensor)\n",
        "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv_bn1 = nn.BatchNorm2d(224,3)\n",
        "        self.conv_bn2 = nn.BatchNorm2d(16)\n",
        "        self.conv_bn3 = nn.BatchNorm2d(32)\n",
        "        self.conv_bn4 = nn.BatchNorm2d(64)\n",
        "        self.conv_bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv_bn6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # linear layer (64 * 4 * 4 -> 133)\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
        "        # linear layer (133 -> 133)\n",
        "        self.fc2 = nn.Linear(512, 20)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.conv_bn2(self.pool(F.relu(self.conv1(x))))\n",
        "        x = self.conv_bn3(self.pool(F.relu(self.conv2(x))))\n",
        "        x = self.conv_bn4(self.pool(F.relu(self.conv3(x))))\n",
        "        x = self.conv_bn5(self.pool(F.relu(self.conv4(x))))\n",
        "        x = self.conv_bn6(self.pool(F.relu(self.conv5(x))))\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 256 * 7 * 7)\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#-#-# You so NOT have to modify the code below this line. #-#-#\n",
        "\n",
        "# instantiate the CNN\n",
        "model_scratch = Net()\n",
        "print(model_scratch)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (conv_bn1): BatchNorm2d(224, eps=3, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=12544, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=20, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOAD MODEL WITHOUT TRAINING"
      ],
      "metadata": {
        "id": "6VqsoLgwmpRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model_scratch.load_state_dict(torch.load('/content/gdrive/MyDrive/WILDLIFE-PROJECT/model_scratch_wildlife.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acB19ecYl7v-",
        "outputId": "1fcd19b8-e5a0-4107-989c-c34223e65c7e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "hRjTc0v-my1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='step-LAST'></a>\n",
        "## Complete Code to Capture input image from Webcam and then Predict the category"
      ],
      "metadata": {
        "id": "pJED0SVhDCN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "MIgFyzVayZDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='step-START'></a>\n",
        "## Start of Testing using Webcam"
      ],
      "metadata": {
        "id": "5EC6Y5lWyUL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript, Image\n",
        "import numpy as np\n",
        "import shutil\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "import re\n",
        "from PIL import Image\n",
        "\n",
        "def find_closest_object(contours, min_area=100):\n",
        "    \"\"\"\n",
        "    Finds the contour with the largest area among contours with area greater than min_area.\n",
        "\n",
        "    Args:\n",
        "        contours: List of contours.\n",
        "        min_area: Minimum area threshold.\n",
        "\n",
        "    Returns:\n",
        "        The contour with the largest area among contours with area greater than min_area.\n",
        "    \"\"\"\n",
        "    max_area = min_area\n",
        "    closest_contour = None\n",
        "\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > min_area and area > max_area:\n",
        "            max_area = area\n",
        "            closest_contour = contour\n",
        "\n",
        "    return closest_contour\n",
        "\n",
        "def draw_contour_box(image, contour):\n",
        "    \"\"\"\n",
        "    Draws a bounding box around the contour on the image.\n",
        "\n",
        "    Args:\n",
        "        image: Input image.\n",
        "        contour: Contour to draw the bounding box around.\n",
        "\n",
        "    Returns:\n",
        "        The image with the bounding box drawn.\n",
        "    \"\"\"\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    return image\n",
        "\n",
        "def take_photo_and_predict(filename='photo.jpg', quality=0.8):\n",
        "    # Take photo with box drawn\n",
        "    js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        capture.textContent = 'Capture';\n",
        "        div.appendChild(capture);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Resize the output to fit the video element.\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        // Wait for Capture to be clicked.\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "        return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "    # Get photo data\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    # Convert JS image data to OpenCV format\n",
        "    img = cv2.imdecode(np.frombuffer(base64.b64decode(data.split(',')[1]), np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale for contour detection\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply Gaussian blur to remove noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    # Threshold the image\n",
        "    _, thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # Find the contour with the largest area\n",
        "    closest_contour = find_closest_object(contours)\n",
        "\n",
        "    # If a contour is found, draw a bounding box around it and predict breed\n",
        "    if closest_contour is not None:\n",
        "        img_with_box = draw_contour_box(img.copy(), closest_contour)\n",
        "\n",
        "        # Save image with box drawn\n",
        "        cv2.imwrite(filename, img_with_box)\n",
        "        print('Saved to {}'.format(filename))\n",
        "\n",
        "        # Predict breed\n",
        "        img = Image.open(filename)\n",
        "        predicted_breed, true_breed = predict_breed(img)\n",
        "        print(\"Predicted Animal:\", predicted_breed, \"\\nTrue Animal:\", true_breed)\n",
        "\n",
        "        # Display the image\n",
        "        imgplot = plt.imshow(img)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print('No objects detected.')\n",
        "        return None\n",
        "\n",
        "    return filename\n",
        "\n",
        "def predict_breed(img):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize]\n",
        "    )\n",
        "\n",
        "    img_tensor = preprocess(img).float()\n",
        "    img_tensor.unsqueeze_(0)  # Insert the new axis at index 0 i.e. in front of the other axes/dims.\n",
        "\n",
        "    if use_cuda:\n",
        "        img_tensor = img_tensor.cuda()\n",
        "\n",
        "    model_scratch.eval()\n",
        "    output = model_scratch(img_tensor)  # Returns a Tensor of shape (batch, num class labels)\n",
        "\n",
        "    # Our prediction will be the index of the class label with the largest value.\n",
        "    predict_index = output.data.cpu().numpy().argmax()\n",
        "\n",
        "    predicted_breed = class_names[predict_index]\n",
        "    true_breed = image_datasets['train'].classes[predict_index]\n",
        "\n",
        "    return (predicted_breed, true_breed)\n",
        "\n",
        "try:\n",
        "    filename = take_photo_and_predict('/content/gdrive/MyDrive/WILDLIFE-PROJECT/input_photo1.jpg')  # Saving to Google Drive\n",
        "    if filename:\n",
        "        print('Moved to /content/gdrive/MyDrive/WILDLIFE-PROJECT/input_photo1.jpg')\n",
        "        # Move the file to the desired location\n",
        "        shutil.move(filename, '/content/gdrive/MyDrive/WILDLIFE-PROJECT/input_photo1.jpg')\n",
        "except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rwtbJAy1qfry",
        "outputId": "c2e27823-4695-4f47-e447-80816f3517fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        // Resize the output to fit the video element.\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "        // Wait for Capture to be clicked.\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/gdrive/MyDrive/WILDLIFE-PROJECT/input_photo1.jpg\n",
            "name 'class_names' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='step-END'></a>\n",
        "## End of Testing"
      ],
      "metadata": {
        "id": "SokiU_Rsq3zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript, Image\n",
        "import numpy as np\n",
        "import shutil\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "import re\n",
        "from PIL import Image\n",
        "\n",
        "# Load the XYZ.h5 model\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the CNN architecture class\n",
        "class XYZModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XYZModel, self).__init__()\n",
        "        # Define the architecture of the XYZ model\n",
        "        # Example:\n",
        "        # self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        # ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass of the XYZ model\n",
        "        pass\n",
        "\n",
        "# Load the XYZ model\n",
        "xyz_model = XYZModel()\n",
        "xyz_model.load_state_dict(torch.load('/path/to/XYZ.h5'))\n",
        "if torch.cuda.is_available():\n",
        "    xyz_model.cuda()\n",
        "\n",
        "# Define other functions and variables used in the code\n",
        "\n",
        "def find_closest_object(contours, min_area=100):\n",
        "    # Function definition remains unchanged\n",
        "\n",
        "def draw_contour_box(image, contour):\n",
        "    # Function definition remains unchanged\n",
        "\n",
        "def take_photo_and_predict(filename='photo.jpg', quality=0.8):\n",
        "    # Function definition remains unchanged\n",
        "\n",
        "def predict_breed(img):\n",
        "    # Function definition remains unchanged\n",
        "\n",
        "try:\n",
        "    filename = take_photo_and_predict('/content/gdrive/MyDrive/WILDLIFE-PROJECT/input_photo1.jpg')\n",
        "    if filename:\n",
        "        print('Moved to /content/gdrive/MyDrive/WILDLIFE-PROJECT/input_photo1.jpg')\n",
        "        shutil.move(filename, '/content/gdrive/MyDrive/WILDLIFE-PROJECT/input_photo1.jpg')\n",
        "except Exception as err:\n",
        "    print(str(err))"
      ],
      "metadata": {
        "id": "YYdj_XOftZ65"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}